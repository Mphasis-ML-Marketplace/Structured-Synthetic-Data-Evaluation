{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08cfb2e6",
   "metadata": {},
   "source": [
    "# Structured Synthetic Data Evaluation\n",
    "\n",
    "Structured Synthetic Data Evaluation is an evaluation framework to validate the data quality and privacy of synthetic data. \n",
    "\n",
    "### Prerequisite\n",
    "\n",
    "To run this algorithm you need to have access to the following AWS Services:\n",
    "- Access to AWS SageMaker and the model package.\n",
    "- An S3 bucket to specify input/output.\n",
    "- Role for AWS SageMaker to access input/output from S3.\n",
    "\n",
    "This sample notebook shows you how to deploy Synthetic Data Evaluation using Amazon SageMaker.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to Synthetic Data Evaluation. If so, skip step: [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "\n",
    "#### Contents:\n",
    "1. [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "2. [Create an endpoint and perform real-time inference](#2.-Create-an-endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   2. [Create input payload](#B.-Create-input-payload)\n",
    "   3. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "   4. [Output Result](#D.-Output-Result)\n",
    "   5. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "3. [Perform batch inference](#3.-Perform-batch-inference) \n",
    "4. [Clean-up](#4.-Clean-up)\n",
    "    1. [Delete the model](#A.-Delete-the-model)\n",
    "    2. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "    \n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d72d58f4",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the model package"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0d9ef26",
   "metadata": {},
   "source": [
    "To subscribe to the model package:\n",
    "1. Open the model package listing page Synthetic Data Evaluation.\n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "121005de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_arn='synth-studio-evaluation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c78891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "from zipfile import ZipFile\n",
    "import uuid\n",
    "import sagemaker as sage\n",
    "from sagemaker import ModelPackage\n",
    "from sagemaker import get_execution_role\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee6391",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "\n",
    "sagemaker_session = sage.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "bucket"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a05b07d1",
   "metadata": {},
   "source": [
    "### 2. Create an endpoint and perform real-time inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb0e8883",
   "metadata": {},
   "source": [
    "If you want to understand how real-time inference with Amazon SageMaker works, see [Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b282198",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"synth-studio-evaluation-1\"\n",
    "\n",
    "content_type = \"application/zip\"\n",
    "\n",
    "real_time_inference_instance_type = \"ml.m5.large\"\n",
    "batch_transform_inference_instance_type = \"ml.m5.large\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28b35a84",
   "metadata": {},
   "source": [
    "#### A. Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b6c84d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.predictor.RealTimePredictor(endpoint, session, content_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "721fd51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a deployable model from model package\n",
    "model = ModelPackage(role=role,\n",
    "                    model_package_arn=model_package_arn, \n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    predictor_cls=predict_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c276420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class RealTimePredictor has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(1, real_time_inference_instance_type, endpoint_name=model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2347e2c",
   "metadata": {},
   "source": [
    "#### B. Create input payload"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1872630",
   "metadata": {},
   "source": [
    "#### Instructions\n",
    "\n",
    "    1) The payload should be in zip format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7629c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"Input.zip\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fadf1b8",
   "metadata": {},
   "source": [
    "#### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbfbfd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"ContentType\": \"application/json\",\r\n",
      "    \"InvokedProductionVariant\": \"AllTraffic\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker-runtime invoke-endpoint --endpoint-name $model_name --body fileb://$file_name --content-type 'application/zip' --region us-east-2 output.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d741f2f",
   "metadata": {},
   "source": [
    "#### D. Output Result\n",
    "\n",
    "- The output file (in json format) contains the following files:\n",
    "\n",
    "    1. 'output.json': Dictionary containing different metrics to evaluate the synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0068f8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Attribute Simiarity': {'CSTest': 0.9999999999999454,\n",
       "  'KSTest': 0.73876953125,\n",
       "  'Evaluation Score': 86.93847656249727},\n",
       " 'Privacy at Risk': {'exact match': 36.45833333333333,\n",
       "  'euclidean': 18.880208333333336},\n",
       " 'Sensitive data retrieval': {'Numerical MLP': 0.16106242369788584,\n",
       "  'Numerical LR': 0.15350315089781724,\n",
       "  'Numerical SVR': 0.1756914127716052},\n",
       " 'Data-driven discovery': {'SVC Detection': 0.15399169921875,\n",
       "  'Logistic Detection': 0.302276611328125},\n",
       " 'Loss of Information': {'%\\\\loss': 0.0}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.getcwd()\n",
    "file_name = 'output.json'\n",
    "\n",
    "with open('output.json', 'r') as f:\n",
    "    json_array = json.load(f)\n",
    "\n",
    "json_array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a92952c",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the endpoint to avoid being charged.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2876524",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor=sage.predictor.Predictor(model_name, sagemaker_session,content_type)\n",
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad2f7916",
   "metadata": {},
   "source": [
    "### 3. Perform batch inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2f7d5ec",
   "metadata": {},
   "source": [
    "In this section, you will perform batch inference using multiple input payloads together. If you are not familiar with batch transform, and want to learn more, see these links:\n",
    "1. [How it works](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-batch-transform.html)\n",
    "2. [How to run a batch transform job](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1c0200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload the batch-transform job input files to S3\n",
    "transform_input_folder = \"data/input/batch\"\n",
    "transform_input = sagemaker_session.upload_data(transform_input_folder, key_prefix=model_name)\n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad5fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the batch inference job\n",
    "transformer = model.transformer(1, batch_transform_inference_instance_type)\n",
    "transformer.transform(transform_input, content_type=content_type)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb8d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ouput is available on the following path\n",
    "transformer.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2b35e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file loaded from bucket\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "s3_conn = boto3.client(\"s3\")\n",
    "bucket_name = \"\"\n",
    "with open(\"output.json\", \"wb\") as f:\n",
    "    s3_conn.download_fileobj(bucket_name, os.path.basename(transformer.output_path)+\"/Input.zip.out\", f)\n",
    "    print(\"Output file loaded from bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7225a603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Attribute Simiarity': {'CSTest': 0.9999999999999454,\n",
       "  'KSTest': 0.73876953125,\n",
       "  'Evaluation Score': 86.93847656249727},\n",
       " 'Privacy at Risk': {'exact match': 36.45833333333333,\n",
       "  'euclidean': 18.880208333333336},\n",
       " 'Sensitive data retrieval': {'Numerical MLP': 0.1709571222603199,\n",
       "  'Numerical LR': 0.15350315089781724,\n",
       "  'Numerical SVR': 0.1756914127716052},\n",
       " 'Data-driven discovery': {'SVC Detection': 0.15483601888020837,\n",
       "  'Logistic Detection': 0.30016072591145837},\n",
       " 'Loss of Information': {'%\\\\loss': 0.0}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.getcwd()\n",
    "file_name = \"output.json\"\n",
    "\n",
    "with open(file_name, \"r\") as f:\n",
    "    json_array = json.load(f)\n",
    "    \n",
    "json_array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "623c9971",
   "metadata": {},
   "source": [
    "### 4. Clean-up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dae9e2ef",
   "metadata": {},
   "source": [
    "#### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "625fb474",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete_model()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba1d4c58",
   "metadata": {},
   "source": [
    "#### B. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0b98952",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
